(i) code structure:

    in file "src" the projects code can be found:
        run_attacks.py:
        the program's main script in part (ii) we describe how to use it.

        loss.py:
        In the report.pdf we have talked about several different approaches which we've experimented with for the calculation of the loss criteria,
        in this folder those implementations can be found.

        plot_results_per_epoch.py:
        A simple script to plot the results of experiments, the value on display is the loss value produced by the VO model.

        utils.py:
        This script parses the program's arguments and runs the attack.
        He have slightly altered this files, changed default values and implemented the ability to split the data into train/eval.

        TartanVO.py,tartanvo_node.py these files we not changed.

        under folder "attacks":
            can be found the attacks used to produce the pert.
            cross_validation.py is a script we've implemented so that we can cross-validate the model with different configurations.
            (an explanation of how to use this script in part (ii))
            the rest of the files in this folder were provided by the course's staff.

        under folder "Datasets":
            can be found the code responsible for processing the datasets used in this project.
            We've slightly altered tartanTrajFlowDataset.py so that two datasets will be produced one for train and one for evaluation.
            the rest of the files in this folder weren't changed.

        under the folder "docker":
            one did not change the content of this folder

        under the folder "evaluator":
            one did not change the content of this folder

        under the folder "models":
            one did not change the content of this folder

        under the folder "Network":
            one did not change the content of this folder
(ii) guide:

    Firstly inorder to train and evaluate the file cross_validation can be ran, a list of values can be provided so that the
    model can be tested with several different configurations.
    lines 6-16:

        epochs = 200 // amount of epochs for each attack
        flow_crits = ['epe'] //different flow criteria ('epe','rmse','mse')
        t_crits = ['partial_rms'] //different t criteria ('partial_rms','mean_partial_rms')
        rot_crit = ['quat_product_1'] // the norm used for the rotation loss ('quat_product_1','quat_product_2')
        rot_factors = [1] // float factor for rot in loss sum
        flow_factors = [15] // float factor flow rot in loss sum
        target_factors = [0.5] // float factor for target in loss sum
        t_factors = [2500] // float factor for t in loss sum
        steps = [0.08] //float step sizes
        learn_data_size = 8 // amount of datasets used for training the rest will be used for evaluation
        max_traj_len = 21 // trajectories length

    to produced the same results as we've displayed in the report simply run run_attacks.py with the arguments:

        --model-name
        tartanvo_1914.pkl
        --kitti
        --custom_data
        --test-dir
        VO_adv_project_train_dataset_8_frames
        --max_traj_len 21
        --batch-size 1
        --worker-num 1
        --save_csv
        --attack pgd
        --attack_k 200
        --alpha 0.08
        --attack_flow_crit epe
        --attack_rot_crit quat_product_1
        --attack_t_crit partial_rms
        --attack_target_t_crit patch
        --attack_norm Linf
        --attack_t_factor 2500
        --attack_rot_factor 1
        --attack_flow_factor 15
        --attack_target_t_factor 0.5
        --max_traj_datasets 8
        --save_best_pert





